{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define schema for Spark ML model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema is identified from the features Vector that was used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "schema = {\"input\":[{\"type\":\"string\",\"name\":\"encounters_encounterclass\"},{\"type\":\"string\",\"name\":\"patient_gender\"},{\"type\":\"string\",\"name\":\"patient_marital\"},{\"type\":\"string\",\"name\":\"patient_ethnicity\"},{\"type\":\"string\",\"name\":\"patient_race\"},{\"type\":\"string\",\"name\":\"encounters_reasoncode\"},{\"type\":\"string\",\"name\":\"encounters_code\"},{\"type\":\"string\",\"name\":\"procedures_code\"},{\"type\":\"double\",\"name\":\"patient_healthcare_expenses\"},{\"type\":\"double\",\"name\":\"patient_healthcare_coverage\"},{\"type\":\"double\",\"name\":\"encounters_total_claim_cost\"},{\"type\":\"double\",\"name\":\"encounters_payer_coverage\"},{\"type\":\"double\",\"name\":\"encounters_base_encounter_cost\"},{\"type\":\"double\",\"name\":\"procedures_base_cost\"},{\"type\":\"long\",\"name\":\"providers_utilization\"},{\"type\":\"double\",\"name\":\"age\"}],\"output\":{\"type\":\"double\",\"name\":\"features\",\"struct\":\"vector\"}}\n",
    "schema_json = json.dumps(schema)\n",
    "print(schema_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SageMaker model from the model artifacts on S3 Bucket "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to update **s3_model_bucket** and **s3_model_bucket_prefix** as per your environment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_bucket = \"\" ## UPDATE with S3 bucket name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls 's3://'$s3_model_bucket'/spark-ml-model' --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UPDATE the S3 prefix from the above output excluding /model.tar.gz\n",
    "s3_model_bucket_prefix = \"spark-ml-model/2020/4/9\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sparkml.model import SparkMLModel\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 location of where you uploaded your trained and serialized SparkML model\n",
    "sparkml_data = 's3://{}/{}/{}'.format(s3_model_bucket, s3_model_bucket_prefix, 'model.tar.gz')\n",
    "model_name = 'sparkml-abalone-' + timestamp_prefix\n",
    "sparkml_model = SparkMLModel(model_data=sparkml_data, \n",
    "                             role=role, \n",
    "                             sagemaker_session=sess, \n",
    "                             name=model_name,\n",
    "                             # passing the schema defined above by using an environment \n",
    "                             #variable that sagemaker-sparkml-serving understands\n",
    "                             env={'SAGEMAKER_SPARKML_SCHEMA' : schema_json})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy SageMaker model for real time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'sparkml-abalone-ep-' + timestamp_prefix\n",
    "sparkml_model.deploy(initial_instance_count=1, instance_type='ml.c4.large', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking the newly created inference endpoint with a payload to transform the data\n",
    "Now we will invoke the endpoint with a valid payload that SageMaker SparkML Serving can recognize. There are three ways in which input payload can be passed to the request:\n",
    "\n",
    "* Pass it as a valid CSV string. In this case, the schema passed via the environment variable will be used to determine the schema. For CSV format, every column in the input has to be a basic datatype (e.g. int, double, string) and it can not be a Spark `Array` or `Vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the below payload with test data as per above defined schema \n",
    "payload = \"outpatient,M,S,hispanic,white,271737000,185347001,430193006,262241.40,2324.88,129.16,64.16,129.16,526.17,16,40\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sess, serializer=csv_serializer,\n",
    "                                content_type=CONTENT_TYPE_CSV, accept=CONTENT_TYPE_CSV)\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Deleting the Endpoint\n",
    "If you do not plan to use this endpoint, then it is a good practice to delete the endpoint so that you do not incur the cost of running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = sess.boto_session\n",
    "sm_client = boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
